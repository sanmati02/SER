# Dataset Parameters
dataset_conf:
  dataset:
    # Minimum audio length to keep (shorter ones are filtered out)
    min_duration: 0.4
    # Maximum audio length (longer ones will be trimmed)
    max_duration: 3
    # Audio sampling rate
    sample_rate: 16000
    # Whether to apply volume normalization
    use_dB_normalization: True
    # Target dB value for volume normalization
    target_dB: -20
    # Path to the normalization scaler file
    scaler_path: 'dataset/standard.m'
  dataLoader:
    # Batch size for training
    batch_size: 64
    # Whether to drop the last incomplete batch
    drop_last: True
    # Number of threads for data loading
    num_workers: 4
  # Path to the training data list
  train_list: 'dataset/train_list_features.txt'
  # Path to the testing data list
  test_list: 'dataset/test_list_features.txt'
  # Path to the label list
  label_list_path: 'dataset/label_list.txt'
  # Special settings for evaluation
  eval_conf:
    # Batch size for evaluation
    batch_size: 1
    # Maximum audio length allowed during evaluation
    max_duration: 5

# Data Preprocessing Parameters
preprocess_conf:
  # Feature extraction method (supported: CustomFeature, Emotion2Vec)
  feature_method: 'CustomFeature'
  method_args:
    granularity: 'utterance'
    feature_type: 'mfcc'

# Model Parameters
model_conf:
  # Model to be used
  model: 'BiLSTM'
  # Model-specific parameters
  model_args:
    # Number of classes; if null, automatically determined from the label list
    num_class: null

# Optimizer Parameters
optimizer_conf:
  # Optimizer to use
  optimizer: 'Adam'
  # Optimizer-specific parameters
  optimizer_args:
    lr: 0.001
    weight_decay: !!float 1e-5
  # Learning rate scheduler (supports PyTorch built-ins and custom WarmupCosineSchedulerLR)
  scheduler: 'WarmupCosineSchedulerLR'
  # Scheduler-specific parameters
  scheduler_args:
    min_lr: !!float 1e-5
    max_lr: 0.001
    warmup_epoch: 5

# Training Parameters
train_conf:
  # Whether to enable automatic mixed precision (AMP)
  enable_amp: False
  # Whether to use the PyTorch 2.0 compiler
  use_compile: False
  # Label smoothing parameter for CrossEntropyLoss
  label_smoothing: 0.0
  # Number of training epochs
  max_epoch: 60
  # Interval (in steps) at which to log training information
  log_interval: 10
